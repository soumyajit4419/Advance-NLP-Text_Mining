{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Text_cosine_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6uhJnvtmI1M",
        "colab_type": "text"
      },
      "source": [
        "# Document Similarity-Embedding Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-wHT04BmI1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOQLMPQKmI1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from nltk.corpus import  stopwords\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E76gURp5cvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndVakvjimI1g",
        "colab_type": "text"
      },
      "source": [
        "## Text Similarity using Count Vectorizer and Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jITHcsemI1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = 'The president greets the press in Chicago'\n",
        "str2 = 'Obama speaks to the media in Illinois'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quR-xnE9mI1h",
        "colab_type": "text"
      },
      "source": [
        "###  Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxCM6KYImI1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXK7nnmkmI1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=[str1,str2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBXTwQ2PmI1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc09477a-37eb-4634-dd40-cf30163a01f8"
      },
      "source": [
        "all_vector=vectorizer.fit_transform(s)\n",
        "all_vector.toarray()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 1, 0, 0, 1, 1, 0, 2, 0],\n",
              "       [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV_3WsS7mI1v",
        "colab_type": "text"
      },
      "source": [
        "### Finding Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l743ukO_mI1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_a=all_vector.toarray()[0]\n",
        "v_b=all_vector.toarray()[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXLQr53mmI1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62ed76a0-7394-4243-91ee-abf63a99a905"
      },
      "source": [
        "cosine_sim=cosine_similarity([v_a],[v_b])\n",
        "print('Similarity of two sentences are equal to',((cosine_sim[0][0])*100),'%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of two sentences are equal to 37.79644730092272 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq6lsHV6mI13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v1 = all_vector.toarray()[0]\n",
        "v2 = all_vector.toarray()[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2OUEgZxmI16",
        "colab_type": "text"
      },
      "source": [
        "### Finding Cosine Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzrV7nltmI17",
        "colab_type": "text"
      },
      "source": [
        "#### Cosine_distance = 1 - cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXzwOmrfmI18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d686c535-1b31-4bb6-8324-606134657919"
      },
      "source": [
        "cosine_dist= distance.cosine(v1,v2)\n",
        "cosine_dist"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6220355269907728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "1A7uvvIWmI1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37636b36-eb4d-4b8f-f8bc-04d3f8c96ff2"
      },
      "source": [
        "print('Similarity of two sentences are equal to',((1-cosine_dist)*100),'%')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of two sentences are equal to 37.79644730092272 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ8JJhPVmI2D",
        "colab_type": "text"
      },
      "source": [
        "## Text Similarity using Globe Embedding and Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJpqE1o5mfVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(a):\n",
        "  text=re.sub('[^a-zA-Z]',' ',a)\n",
        "  text=text.lower()\n",
        "  text=text.split()\n",
        "  text=list([word for word in text])\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EudKw6NmI2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "464a94fd-78b5-4a2a-8d76-3da09b897c9c"
      },
      "source": [
        "# Note this is the 100 dimension version of GloVe from Stanford\n",
        "# I unzipped and hosted it on my site to make this notebook easier\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n",
        "embeddings_index = {};\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-09 15:04:25--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "/tmp/glove.6B.100d. 100%[===================>] 331.04M   131MB/s    in 2.5s    \n",
            "\n",
            "2020-05-09 15:04:28 (131 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgGrfJQAtP25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strl1=clean_text(str1)\n",
        "strl2=clean_text(str2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLIf2DmQyCZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58a41c23-0544-4e02-8cd6-6f64b31826dc"
      },
      "source": [
        "strl1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'president', 'greets', 'the', 'press', 'in', 'chicago']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4KrW3TDtUFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd38e925-66c0-4757-a761-e92d132d504f"
      },
      "source": [
        "strl2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['obama', 'speaks', 'to', 'the', 'media', 'in', 'illinois']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBQEOVLnyG-r",
        "colab_type": "text"
      },
      "source": [
        "### Creating Vectors from globe \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obOsfL2PmYUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect1=np.mean([embeddings_index[word] for word in strl1],axis=0)\n",
        "vect2=np.mean([embeddings_index[word] for word in strl2],axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEKvGq_0yQS0",
        "colab_type": "text"
      },
      "source": [
        "### Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHogcyQIuYA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cosine_similar=cosine_similarity([vect1],[vect2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6MA6Ta7ugGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8603f932-5a26-4fb0-9fdd-8cc6f3319c69"
      },
      "source": [
        "cosine_similar"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92722815]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBPEXLnPycb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "771832db-597b-4b1e-a311-2d1617e9115c"
      },
      "source": [
        "print('Similarity of two sentences are equal to',((cosine_similar[0][0])*100),'%')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of two sentences are equal to 92.72281527519226 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es1rNGRhyYwr",
        "colab_type": "text"
      },
      "source": [
        "### Cosine Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D3aZ_I1uiDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " cosine_dist = distance.cosine(vect1, vect2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db-OxwtLyu0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8261fc75-ef3c-46de-ca1c-fa03568a176f"
      },
      "source": [
        "cosine_dist"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07277172803878784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Zxw96hv0QK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99dc3f49-31d9-46bc-809f-9fa0f430fb9b"
      },
      "source": [
        "print('Similarity of two sentences are equal to',((1-cosine_dist)*100),'%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of two sentences are equal to 92.72282719612122 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY3eHv58yycg",
        "colab_type": "text"
      },
      "source": [
        "## Globe Embedding With Cosine Similarity gives more accurate results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSxbYE8Y06kk",
        "colab_type": "text"
      },
      "source": [
        "## Building Functions to Implement Cosine simialrity with Globe Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9juLFZ20485",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = \"I was given a card by her in the garden.\"\n",
        "str2 = \"In the garden, she gave me a card.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8uyQK9N31_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "904f7932-75dc-4453-c2d5-6a6ed1257d1c"
      },
      "source": [
        "strl1=clean_text(str1)\n",
        "strl1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'was', 'given', 'a', 'card', 'by', 'her', 'in', 'the', 'garden']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8A2R_pv-KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def similarity_predict(str1,str2):\n",
        "  strl1=clean_text(str1)\n",
        "  strl2=clean_text(str2)\n",
        "  vect1=np.mean([embeddings_index[word] for word in strl1],axis=0)\n",
        "  vect2=np.mean([embeddings_index[word] for word in strl2],axis=0)\n",
        "  cosine_similar=cosine_similarity([vect1],[vect2])\n",
        "  return cosine_similar[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXSf5ZpO3iyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad173ed9-01a3-47b5-c527-72c886c7d93f"
      },
      "source": [
        "prediction=similarity_predict(str1,str2)\n",
        "prediction"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98466194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4YExfwr9QOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = \"A cemetery is a place where dead people's bodies or their ashes are buried.\"\n",
        "str2 = \"A graveyard is an area of land ,sometimes near a church, where dead people are buried.\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnk6lYuY9iIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "549795bd-726b-4e15-aff3-dce5a3e1ad3c"
      },
      "source": [
        "prediction=similarity_predict(str1,str2)\n",
        "prediction"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96416223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}