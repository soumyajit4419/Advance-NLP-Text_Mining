{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Using Latent Dirichlet Allocation\n",
    "#### LDA is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the dataset\n",
    "#### The dataset used is the 20newsgroup dataset that is available from sklearn. This dataset has news articles grouped into 20 news categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle = True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics of different news groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=newsgroups_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i\\'m in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni\\'m looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?\\n\\n* what\\'s the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i\\'ve only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\\\  twillis@ecn.purdue.edu    \\\\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "\n",
    "### Perform the following steps:\n",
    "\n",
    "#### Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "#### Words that have fewer than 3 characters are removed.\n",
    "#### All stopwords are removed.\n",
    "#### Words are lemmatized - words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "#### Words are stemmed - words are reduced to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=[]\n",
    "for a in data:\n",
    "    a=a.lower()\n",
    "    text=re.sub('[^a-z]',' ',a)\n",
    "    text=text.split(' ')\n",
    "    text=[lemma.lemmatize(word) for word in text if word not in stopwords.words('english') and len(word) > 3]\n",
    "    text=' '.join(text)\n",
    "    new_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twillis purdue thomas willis subject question organization purdue university engineering computer network distribution line well folk plus finally gave ghost weekend starting life back sooo market machine sooner intended looking picking powerbook maybe bunch question hopefully somebody answer anybody know dirt next round powerbook introduction expected heard supposed make appearence summer heard anymore since access macleak wondering anybody info anybody heard rumor price drop powerbook line like one went recently impression display could probably swing disk rather really feel much better display look great store really good could solicit opinion people worth taking disk size money active display realize real subjective question played around machine computer store breifly figured opinion somebody actually us machine daily might prove helpful well hellcat perform thanks bunch advance info could email post summary news reading time premium final around corner willis twillis purdue purdue electrical engineering conviction dangerous enemy truth lie nietzsche'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vector.fit_transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 73210)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sparse matrix to gensim corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping from word IDs to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map={}\n",
    "for k,v in vector.vocabulary_.items():\n",
    "    id_map[v]=k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus,id2word=id_map,num_topics=8,passes=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_words = lda_model.print_topics(num_topics=8,num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0\n",
      "0.022*\"drive\" + 0.016*\"card\" + 0.011*\"scsi\" + 0.010*\"disk\" + 0.009*\"driver\" + 0.008*\"problem\" + 0.008*\"system\" + 0.007*\"line\" + 0.007*\"subject\" + 0.007*\"organization\"\n",
      "\n",
      "\n",
      "topic 1\n",
      "0.012*\"chip\" + 0.012*\"encryption\" + 0.011*\"clipper\" + 0.007*\"government\" + 0.007*\"key\" + 0.007*\"security\" + 0.006*\"system\" + 0.006*\"public\" + 0.005*\"privacy\" + 0.005*\"escrow\"\n",
      "\n",
      "\n",
      "topic 2\n",
      "0.021*\"line\" + 0.020*\"subject\" + 0.019*\"organization\" + 0.012*\"posting\" + 0.011*\"nntp\" + 0.011*\"host\" + 0.011*\"article\" + 0.011*\"writes\" + 0.010*\"university\" + 0.007*\"would\"\n",
      "\n",
      "\n",
      "topic 3\n",
      "0.011*\"game\" + 0.009*\"team\" + 0.008*\"line\" + 0.008*\"year\" + 0.008*\"subject\" + 0.007*\"organization\" + 0.007*\"writes\" + 0.006*\"player\" + 0.005*\"article\" + 0.005*\"play\"\n",
      "\n",
      "\n",
      "topic 4\n",
      "0.010*\"people\" + 0.009*\"would\" + 0.006*\"think\" + 0.006*\"writes\" + 0.006*\"subject\" + 0.005*\"line\" + 0.005*\"organization\" + 0.005*\"know\" + 0.005*\"article\" + 0.005*\"christian\"\n",
      "\n",
      "\n",
      "topic 5\n",
      "0.008*\"people\" + 0.006*\"state\" + 0.006*\"government\" + 0.005*\"armenian\" + 0.005*\"would\" + 0.005*\"right\" + 0.004*\"said\" + 0.004*\"year\" + 0.003*\"president\" + 0.003*\"american\"\n",
      "\n",
      "\n",
      "topic 6\n",
      "0.012*\"file\" + 0.012*\"window\" + 0.009*\"line\" + 0.008*\"program\" + 0.007*\"subject\" + 0.005*\"system\" + 0.005*\"image\" + 0.005*\"organization\" + 0.005*\"version\" + 0.004*\"graphic\"\n",
      "\n",
      "\n",
      "topic 7\n",
      "0.008*\"space\" + 0.006*\"nasa\" + 0.005*\"subject\" + 0.005*\"organization\" + 0.005*\"would\" + 0.005*\"line\" + 0.004*\"time\" + 0.004*\"year\" + 0.004*\"article\" + 0.004*\"like\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for no,top in topics_words:\n",
    "    print('topic',no)\n",
    "    print(top)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of the topics\n",
    "#### Using the words in each topic and their categories\n",
    "\n",
    "\n",
    "* Hardware\n",
    "* Encryption\n",
    "* Sports\n",
    "* Religion\n",
    "* Politics\n",
    "* Graphics\n",
    "* Space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Matjaz.Gams@IJS.si\n",
      "Subject: ``Call for Papers for INFORMATIKA'' Vol. 17 No. 2\n",
      "Originator: abrodnik@watdragon.uwaterloo.ca\n",
      "Organization: Jozef Stefan Institute, Ljubljana, Slovenia\n",
      "Lines: 69\n",
      "\n",
      "This is an invitation to send articles to the Informatica magazine.\n",
      "The first fully international issue has been published and echoes \n",
      "are quite favourable. For any information, contact (matjaz.gams@ijs.si). \n",
      "\n",
      "Dear Colleague,                                        April 25, 1993\n",
      "\n",
      "Number 1 of volume 17 of Informatica is now out of print and some of you \n",
      "will receive it in a week or so. As you will see, the journal is structured\n",
      "in the following way: the editorial (first page); profiles (second page\n",
      "-- biography of an editor, in this issue, Terry Winograd); the edited\n",
      "part of papers (pp. 3-80); mission and research reports (A plan for\n",
      "knowledge archives project in Japan and CSLI in Stanford, pp. 81-100);\n",
      "and news and announcements (pp. 101-108). This structure is mentioned to\n",
      "give you a suggestion how could you help to make the contents of the\n",
      "journal significant, diverse, and interesting, bringing your own views\n",
      "into the discourse.\n",
      "   A great emphasis is given to the so-called editorial page. This page\n",
      "expresses an opinion (belief) of the writing editor to some problems\n",
      "within the scope of computing and informatics, extending into other\n",
      "concerning disciplines, e.g. cybernetics, advanced AI, cognitive sciences,\n",
      "mind, informationally concerned neural sciences, advanced technology \n",
      "(e.g. photonics), etc. I asked professor Terry Winograd to write this\n",
      "page for Number 2. I certainly would appreciate very much to get\n",
      "suggestions or possible offers from other editors, who like to express\n",
      "their strong (directed) beliefs concerning a future development of the\n",
      "area in question.\n",
      "   On the second page of each Number an editor's profile is published.\n",
      "The aim of the profile is twofold: to show his/her professional \n",
      "achievements, interests, scientific, and philosophical orientation on\n",
      "one side; to narrate his/her life story in the environments in which\n",
      "editors has lived and live on the other side. This kind of story should\n",
      "be instructive, adequately factically faced, contributing to the \n",
      "understanding of circumstances in which editors have to act and live.\n",
      "   The edited part (edited papers) is still critical. I would like to have\n",
      "a stock of accepted papers in advance, so the issuing dates of a particular\n",
      "number can be fixed (e.g. January, April, July, and October). In situation\n",
      "right now, I ask you to help me with contributions of yours or your\n",
      "colleagues, collaborators, students, etc. Some critical views to the\n",
      "contemporary development of computing and informatics are appreciated.\n",
      "A special emphasis should be given also to originality by which fresh\n",
      "ideas are coming into the circulation of different professional communities.\n",
      "   Reports of different occasions (symposia, conferences, meetings, etc.)\n",
      "and particularly on new books, papers, and interesting events are welcome.\n",
      "You can send these news immediately (also by your secretary) by e-mail.\n",
      "On the other hand, you can send books and other publications (annual\n",
      "reports, journals, calls for papers, etc.) for reviewing and publishing\n",
      "in Informatica. We in the editorial staff will manage the rest.\n",
      "   E-mail is functioning satisfactorily, so please use it in every respect.\n",
      "You can submit editorial notes, profiles, reports, news and even complete\n",
      "papers written in standard LaTex format (especially formulas). We received\n",
      "several final (corrected) texts in Number 1 from different sites (US,\n",
      "Russia, etc.). In this way, you can compose reports from already typed\n",
      "texts, using your own choice and editing, and submit them to the contact\n",
      "person (matjaz.gams@ijs.si), who is always being on your disposal. So,\n",
      "you will receive a prompt confirmation and any information concerning\n",
      "our common interest and job.\n",
      "\n",
      "At the end, please do not forget: we need your cooperation and help in\n",
      "every mentioned respect. The aim of Informatica is to open various\n",
      "possibilities of communication concerning strong scientific and \n",
      "philosophical orientations as well as those coming up, still unrevealed,\n",
      "and on the way to become significant. Please, do not apprehend to give\n",
      "proposals, suggestions, and, certainly, contributions via the e-mail\n",
      "and by other means.\n",
      "\n",
      "Sincerely yours,\n",
      "\n",
      "Anton P. \"Zeleznikar\n",
      "Editor-in-chief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num=20\n",
    "unseen_document = newsgroups_test.data[num]\n",
    "print(unseen_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_test.target[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(newsgroups_test.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(a):\n",
    "    a = a.lower()\n",
    "    text = re.sub('[^a-z]', ' ', a)\n",
    "    text = text.split(' ')\n",
    "    text = [lemma.lemmatize(word) for word in text if word not in stopwords.words('english') and len(word) > 3]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matjaz gam subject call paper informatika originator abrodnik watdragon uwaterloo organization jozef stefan institute ljubljana slovenia line invitation send article informatica magazine first fully international issue published echo quite favourable information contact matjaz gam dear colleague april number volume informatica print receive week journal structured following editorial first page profile second page biography editor issue terry winograd edited part paper mission research report plan knowledge archive project japan csli stanford news announcement structure mentioned give suggestion could help make content journal significant diverse interesting bringing view discourse great emphasis given called editorial page page express opinion belief writing editor problem within scope computing informatics extending concerning discipline cybernetics advanced cognitive science mind informationally concerned neural science advanced technology photonics asked professor terry winograd write page number certainly would appreciate much suggestion possible offer editor like express strong directed belief concerning future development area question second page number editor profile published profile twofold show professional achievement interest scientific philosophical orientation side narrate life story environment editor lived live side kind story instructive adequately factically faced contributing understanding circumstance editor live edited part edited paper still critical would like stock accepted paper advance issuing date particular number fixed january april july october situation right help contribution colleague collaborator student critical view contemporary development computing informatics appreciated special emphasis given also originality fresh idea coming circulation different professional community report different occasion symposium conference meeting particularly book paper interesting event welcome send news immediately also secretary mail hand send book publication annual report journal call paper reviewing publishing informatica editorial staff manage rest mail functioning satisfactorily please every respect submit editorial note profile report news even complete paper written standard latex format especially formula received several final corrected text number different site russia compose report already typed text using choice editing submit contact person matjaz gam always disposal receive prompt confirmation information concerning common interest please forget need cooperation help every mentioned respect informatica open various possibility communication concerning strong scientific philosophical orientation well coming still unrevealed become significant please apprehend give proposal suggestion certainly contribution mail mean sincerely anton zeleznikar editor chief'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_document=clean_text(unseen_document)\n",
    "unseen_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 0.021908386),\n",
       "  (2, 0.019237904),\n",
       "  (4, 0.18396628),\n",
       "  (5, 0.2053172),\n",
       "  (6, 0.3739754),\n",
       "  (7, 0.19483472)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = vector.transform([unseen_document])\n",
    "y_corpus = gensim.matutils.Sparse2Corpus(y, documents_columns=False)\n",
    "prediction = lda_model.get_document_topics(y_corpus)\n",
    "list(sorted(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modle Predicted 97% Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model correctly classifies the unseen document with 'x'% probability to the X category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: nhmas@gauss.med.harvard.edu (Mark Shneyder 432-4219)\n",
      "Subject: Re: BUFFALO 4, Boston 0: Defense!!\n",
      "Organization: HMS\n",
      "Lines: 27\n",
      "NNTP-Posting-Host: gauss.med.harvard.edu\n",
      "\n",
      "In article <1993Apr21.142357.14164@alchemy.chem.utoronto.ca> golchowy@alchemy.chem.utoronto.ca (Gerald Olchowy) writes:\n",
      ">Fuhr is proving the Fuhr-bashers wrong, but Boston is an awfully\n",
      ">good team.\n",
      ">\n",
      "\n",
      "Yeh,but :\n",
      "\n",
      "1.Biran Sutter's playoff record as the head coach in St.L wasn't very\n",
      "impressive. His Blues teams were eliminated very early in the playoffs.\n",
      "It doesn't look like this trend will change with the Bruins.\n",
      "\n",
      "2. Bruins have never come back to win after falling behind 2-0 in their\n",
      "entire 68-year history. It doesn't look like Buffalo will just lose\n",
      "their next two games at the Aud with the way Fuhr has been standing on\n",
      "his head.\n",
      "\n",
      "Basically,the Bruins will be on the golf course by next weekend.\n",
      "Also,it seems like the whole Boston area has gone baseball crazy after\n",
      "an incredibly great start by the Red Sox(best record in their major\n",
      "leagues as of now). I would say that 70% of the callers to the Bruins'\n",
      "flagship station(SportsRadio 590) are talking about the Red Sox,about\n",
      "15% are yapping about the Patriots' upcoming draft,10% are on the Celtics\n",
      "and about 5% are on the Bruins.\n",
      "Somehow,no one around here is really schocked the way Bruins are folding\n",
      "early.\n",
      "\n",
      "-PPV Mark\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num=158\n",
    "unseen_document = newsgroups_test.data[num]\n",
    "print(unseen_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_test.target[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nhmas gauss harvard mark shneyder subject buffalo boston defense organization line nntp posting host gauss harvard article alchemy chem utoronto golchowy alchemy chem utoronto gerald olchowy writes fuhr proving fuhr bashers wrong boston awfully good team biran sutter playoff record head coach impressive blue team eliminated early playoff look like trend change bruin bruin never come back falling behind entire year history look like buffalo lose next game fuhr standing head basically bruin golf course next weekend also seems like whole boston area gone baseball crazy incredibly great start best record major league would caller bruin flagship station sportsradio talking yapping patriot upcoming draft celtic bruin somehow around really schocked bruin folding early mark'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_document=clean_text(unseen_document)\n",
    "unseen_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 0.07447449), (3, 0.902919), (5, 0.01685181)]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = vector.transform([unseen_document])\n",
    "y_corpus = gensim.matutils.Sparse2Corpus(y, documents_columns=False)\n",
    "prediction = lda_model.get_document_topics(y_corpus)\n",
    "list(sorted(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modle Predicted 90% Sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Saving The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('topic_finding')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
